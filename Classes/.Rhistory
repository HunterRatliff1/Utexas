sapply(c("ggplot2", "dplyr", "lubridate", "reshape2", "magrittr", "stringi", "RColorBrewer", "tm", "openNLP", "knitr", "SnowballC",
"tidyr", "ggthemes", "scales", "RCurl", "gridExtra", "googlesheets", "xtable"), require, character.only=TRUE)
# Citation functions
# Get GOV Sheet from local source
df.gov <- read.csv("GOV.csv")
# Download my notes
df.gov$Notes         <- sapply(df.gov$URL, function(x) readLines(textConnection(getURL(paste0(x, "/export?format=txt")))))
names(df.gov$Notes)  <- df.gov$Topic
# Make notes a corpus & apply transformations
Corpus.gov <- lapply(df.gov$Notes, stri_flatten, collapse = " ") %>%
VectorSource() %>% Corpus() %>%
tm_map(content_transformer(function(x) gsub("GOV310L \\| Unit II", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("American and Texas Government \\| GOV 310L", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HUNTER RATLIFF", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HunterRatliff1@gmail.com", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("/", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("-", " ", x))) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stripWhitespace)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(removeWords, c("gov", "hunter", "ratliff", "hunterratliffgmailcom"))
setwd("~/Github/utexas/Classes")
# Get GOV Sheet from local source
df.gov <- read.csv("GOV.csv")
# Download my notes
df.gov$Notes         <- sapply(df.gov$URL, function(x) readLines(textConnection(getURL(paste0(x, "/export?format=txt")))))
names(df.gov$Notes)  <- df.gov$Topic
# Make notes a corpus & apply transformations
Corpus.gov <- lapply(df.gov$Notes, stri_flatten, collapse = " ") %>%
VectorSource() %>% Corpus() %>%
tm_map(content_transformer(function(x) gsub("GOV310L \\| Unit II", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("American and Texas Government \\| GOV 310L", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HUNTER RATLIFF", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HunterRatliff1@gmail.com", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("/", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("-", " ", x))) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stripWhitespace)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(removeWords, c("gov", "hunter", "ratliff", "hunterratliffgmailcom"))
source("/Users/main/Github/utexas/Classes/findMatchingTerms.R")
source("/Users/main/Github/utexas/Classes/vocab_network.R")
df.vocab <- loadVocab()
found.dtm <- findMatchingTerms(vocab_list=df.vocab$vocab_search,
notes_corpus=Corpus.gov,
TermsToAdd = findFreqTerms(TermDocumentMatrix(Corpus.gov), 10))
found.dtm$dimnames$Docs <- as.character(df.gov$Topic) # Label Doc by Topic of the lecture
# Set seed to make the layout reproducible
set.seed(3952)
require(igraph)
g <- get_igraph(matrix=t(as.matrix(found.dtm)))
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
prop <- cluster_label_prop(g)
plot(prop, g, layout=layout.auto)
V(g)$shape     <- "rectangle"
plot(prop, g, layout=layout.auto)
V(g)$size      <- 1 * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size      <- 2 * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size      <- 2.2 * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$label.cex
V(g)$size      <- 2.5 * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size2     <- 1# * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size2     <- 3# * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size2     <- 5# * nchar(V(g)$label) #* V(g)$label.cex + 4
plot(prop, g, layout=layout.auto)
V(g)$size2     <- 10# * nchar(V(g)$label) #* V(g)$label.cex + 4
prop <- cluster_label_prop(g)
plot(prop, g, layout=layout.auto)
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree)
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
plot(prop, g, layout=layout.auto)
V(g)$size2     <- 9 * V(g)$label.cex
plot(prop, g, layout=layout.auto)
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 1
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
plot(prop, g, layout=layout.auto)
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.2
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
plot(prop, g, layout=layout.auto)
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
plot(prop, g, layout=layout.auto)
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
betweenness <- cluster_edge_betweenness(g)
plot(betweenness, g, layout=layout.auto)
found.dtm <- findMatchingTerms(vocab_list=df.vocab$vocab_search, notes_corpus=Corpus.gov, TermsToAdd = NA)
found.dtm$dimnames$Docs <- as.character(df.gov$Topic) # Label Doc by Topic of the lecture
set.seed(3952)
require(igraph)
g <- get_igraph(matrix=t(as.matrix(found.dtm)))
# Remove loops, set labels and degrees of vertices
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
# Sizes
V(g)$shape     <- "rectangle"
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
# Colors
# V(g)$label.color <- "#C0C0C0"  # Light grey
# V(g)$label.color <- "#25383C"  # Dark Slate Grey
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
betweenness <- cluster_edge_betweenness(g)
plot(betweenness, g, layout=layout.auto)
d3heatmap::d3heatmap(as.matrix(found.dtm), scale = "column")
# Get AFR Sheet from local source
df.afr <- read.csv("AFR.csv")
# Download my notes
df.afr$Notes         <- sapply(df.afr$URL, function(x) readLines(textConnection(getURL(paste0(x, "/export?format=txt")))))
names(df.afr$Notes)  <- df.afr$Topic
# Make notes a corpus & apply transformations
Corpus.afr <- lapply(df.afr$Notes, stri_flatten, collapse = " ") %>%
VectorSource() %>% Corpus() %>%
tm_map(content_transformer(function(x) gsub("AFR301 \\| Unit II", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("African American Culture \\| AFR 301", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HUNTER RATLIFF", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("HunterRatliff1@gmail.com", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("/", " ", x))) %>%
tm_map(content_transformer(function(x) gsub("-", " ", x))) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stripWhitespace)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(removeWords, c("gov", "hunter", "ratliff", "hunterratliffgmailcom", "afr", "unit"))
# # List of popular terms
# words <- TermDocumentMatrix(Notes) %>% findFreqTerms(lowfreq=3)
#
# # Build Term Document Matrix
# TDM <- Notes %>% tm_map(stemDocument) %>% TermDocumentMatrix()
getTDM_sparse <- function(Corpus, df, sparsity) {
if (!require("devtools")) install.packages("devtools")
devtools::install_github("rstudio/d3heatmap")
require(d3heatmap)
tdm.stem   <- Corpus %>% tm_map(stemDocument) %>% TermDocumentMatrix()
words      <- Corpus %>% TermDocumentMatrix() %>% Terms()
tdms                <- removeSparseTerms(tdm.stem, sparsity)
tdms$dimnames$Terms <- stemCompletion(Terms(tdms), dictionary = words) %>% as.character()
tdms$dimnames$Docs <- df$Topic
tdms$dimnames$Terms <- as.character(tdms$dimnames$Terms)
return(tdms)
}
tdms.afr <- getTDM_sparse(Corpus.afr, df.afr, 0.55)
set.seed(3952)
require(igraph)
g <- get_igraph(matrix=t(as.matrix(tdms.afr)))
# Remove loops, set labels and degrees of vertices
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
# Sizes
V(g)$shape     <- "rectangle"
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
# Colors
# V(g)$label.color <- "#C0C0C0"  # Light grey
# V(g)$label.color <- "#25383C"  # Dark Slate Grey
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
prop <- cluster_label_prop(g)
plot(prop, g, layout=layout.auto)
g <- get_igraph(matrix=as.matrix(tdms.afr))
# Remove loops, set labels and degrees of vertices
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
# Sizes
V(g)$shape     <- "rectangle"
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
# Colors
# V(g)$label.color <- "#C0C0C0"  # Light grey
# V(g)$label.color <- "#25383C"  # Dark Slate Grey
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
prop <- cluster_label_prop(g)
plot(prop, g, layout=layout.auto)
tdms.afr <- getTDM_sparse(Corpus.afr, df.afr, 0.7)
getTDM_sparse <- function(Corpus, df, sparsity) {
tdm.stem   <- Corpus %>% tm_map(stemDocument) %>% TermDocumentMatrix()
words      <- Corpus %>% TermDocumentMatrix() %>% Terms()
tdms                <- removeSparseTerms(tdm.stem, sparsity)
tdms$dimnames$Terms <- stemCompletion(Terms(tdms), dictionary = words) %>% as.character()
tdms$dimnames$Docs <- df$Topic
tdms$dimnames$Terms <- as.character(tdms$dimnames$Terms)
return(tdms)
}
source("/Users/main/Github/utexas/Classes/vocab_network.R")
tdms.afr <- getTDM_sparse(Corpus.afr, df.afr, 0.7)
# Set seed to make the layout reproducible
set.seed(3952)
require(igraph)
g <- get_igraph(matrix=as.matrix(tdms.afr))
# Remove loops, set labels and degrees of vertices
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
# Sizes
V(g)$shape     <- "rectangle"
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
# Colors
# V(g)$label.color <- "#C0C0C0"  # Light grey
# V(g)$label.color <- "#25383C"  # Dark Slate Grey
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
# # plot the graph a few layouts
# layout1 <- layout.fruchterman.reingold(g)
# plot(g, layout=layout1)
# Clusters
# betweenness <- cluster_edge_betweenness(g)
# fast_greedy <- cluster_fast_greedy(g)
prop <- cluster_label_prop(g)
plot(prop, g, layout=layout.auto)
# plot(betweenness, g, layout=layout.auto)
# d3heatmap::d3heatmap(as.matrix(found.dtm), scale = "column")
plot( g, layout=layout.auto)
tdms.afr <- getTDM_sparse(Corpus.afr, df.afr, 0.8)
# Set seed to make the layout reproducible
set.seed(3952)
require(igraph)
g <- get_igraph(matrix=as.matrix(tdms.afr))
# Remove loops, set labels and degrees of vertices
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
# Sizes
V(g)$shape     <- "rectangle"
V(g)$label.cex <- 0.5 * V(g)$degree / max(V(g)$degree) + 0.3
V(g)$size      <- 2.5 * nchar(V(g)$label) * V(g)$label.cex
V(g)$size2     <- 9 * V(g)$label.cex
# Colors
# V(g)$label.color <- "#C0C0C0"  # Light grey
# V(g)$label.color <- "#25383C"  # Dark Slate Grey
V(g)$frame.color <- NA
egam <- (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color <- rgb(.5, .5, 0, egam)
E(g)$width <- egam
# # plot the graph a few layouts
# layout1 <- layout.fruchterman.reingold(g)
# plot(g, layout=layout1)
# Clusters
# betweenness <- cluster_edge_betweenness(g)
# fast_greedy <- cluster_fast_gr
plot( g, layout=layout.auto)
betweenness <- cluster_edge_betweenness(g)
plot(betweenness, g, layout=layout.auto)
plot(betweenness, g)
betweenness
